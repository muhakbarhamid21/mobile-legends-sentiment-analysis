{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Text Processing & NLP\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility & System\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O Handling\n",
    "from io import StringIO\n",
    "\n",
    "# NLP Processing (Tokenization, Stopwords, Lemmatization)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import download as nltk_download\n",
    "\n",
    "# Word Embeddings & Language Models\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Imbalanced Data Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Feature Engineering (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep Learning (TensorFlow & Keras)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, \n",
    "    LSTM, Bidirectional, GRU\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Visualization\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/mlbb_reviews2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irrelevant Columns Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['reviewId', 'userName', 'userImage', 'thumbsUpCount', 'reviewCreatedVersion', 'replyContent', 'repliedAt', 'appVersion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Folding\n",
    "\n",
    "Convert all text in content to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_casefolding'] = data['content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Emojis & Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji_with_library(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "data['content_no_emoji'] = data['content_casefolding'].apply(remove_emoji_with_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Mentions\n",
    "\n",
    "Remove mentions like @username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_mentions'] = data['content_no_emoji'].apply(\n",
    "    lambda text: re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Hashtags\n",
    "\n",
    "Remove hashtags such as #awesome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_hastags'] = data['content_no_mentions'].apply(\n",
    "    lambda text: re.sub(r'#[A-Za-z0-9]+', '', text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLs\n",
    "\n",
    "Remove web links from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_urls'] = data['content_no_hastags'].apply(\n",
    "    lambda text: re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Numbers\n",
    "\n",
    "Remove all numeric values from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_numbers'] = data['content_no_urls'].apply(\n",
    "    lambda text: re.sub(r'[0-9]+', '', text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Superscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_superscript'] = data['content_no_numbers'].apply(\n",
    "    lambda text: re.sub(r'[\\u2070-\\u209F]', '', text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation\n",
    "\n",
    "Remove punctuation marks from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_punctuation'] = data['content_no_superscript'].apply(\n",
    "    lambda text: text.translate(str.maketrans('', '', string.punctuation))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Newlines with Spaces\n",
    "\n",
    "Replace newline characters (\\n) with spaces to keep the text in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_newlines'] = data['content_no_punctuation'].apply(\n",
    "    lambda text: text.replace('\\n', ' ')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Mulltiple Spaces\n",
    "\n",
    "Replace multiple consecutive spaces with a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_multiplespaces'] = data['content_no_newlines'].apply(\n",
    "    lambda text: re.sub(r'\\s+', ' ', text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Leading & Trailing Spaces\n",
    "\n",
    "Remove unnecessary spaces at the beginning and end of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_unnecessaryspaces'] = data['content_no_multiplespaces'].apply(\n",
    "    lambda text: text.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_tokenized'] = data['content_no_unnecessaryspaces'].apply(lambda text: word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slang Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = pd.read_csv('../lexicon/colloquial-indonesian-lexicon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[['slang', 'formal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = dict(zip(lexicon['slang'], lexicon['formal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_slang(tokens, mapping):\n",
    "    return [mapping.get(token, token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_slangnormalized'] = data['content_tokenized'].apply(\n",
    "    lambda tokens: normalize_slang(tokens, slang_dict)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['content_tokenized', 'content_slangnormalized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listStopwords = set(stopwords.words('indonesian'))\n",
    "listStopwords1 = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listStopwords = listStopwords.union(listStopwords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = pd.read_csv('../stoplist/stopwordbahasa.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_from_csv = set(stoplist[0].astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listStopwords = listStopwords.union(stopwords_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word.lower() not in listStopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_no_stopwords'] = data['content_slangnormalized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['content_slangnormalized', 'content_no_stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"id\")\n",
    "nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"lookup\"})\n",
    "nlp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_lemmatized'] = data['content_no_stopwords'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['content_no_stopwords', 'content_lemmatized']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_clean'] = data['content_lemmatized'].apply(lambda tokens: \" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_positive = dict()\n",
    "\n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "for row in reader:\n",
    "    lexicon_positive[row[0]] = int(row[1])\n",
    "\n",
    "lexicon_negative = dict()\n",
    "\n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
    "reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "for row in reader:\n",
    "    lexicon_negative[row[0]] = int(row[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "    score = 0\n",
    "\n",
    "    for word in text:\n",
    "        if (word in lexicon_positive):\n",
    "            score = score + lexicon_positive[word]\n",
    "\n",
    "    for word in text:\n",
    "        if (word in lexicon_negative):\n",
    "            score = score + lexicon_negative[word]\n",
    "\n",
    "    polarity=''\n",
    "\n",
    "    if (score >= 0):\n",
    "        polarity = 'positive'\n",
    "    elif (score <= -7):\n",
    "        polarity = 'negative'\n",
    "    else:\n",
    "        polarity = 'neutral'\n",
    "\n",
    "    return score, polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data['content_lemmatized'].apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))\n",
    "data['sentiment_score'] = results[0]\n",
    "data['sentiment'] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_numeric'] = label_encoder.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = data['sentiment'].value_counts().reset_index()\n",
    "sentiment_counts.columns = ['sentiment', 'count']\n",
    "\n",
    "fig = px.bar(\n",
    "    sentiment_counts,\n",
    "    x='sentiment',\n",
    "    y='count',\n",
    "    title='Sentiment Counts',\n",
    "    labels={'sentiment': 'Sentiment', 'count': 'Count'},\n",
    "    color='sentiment',\n",
    "    color_discrete_map={'Positive': 'green', 'Neutral': 'orange', 'Negative': 'red'}, \n",
    "    text='count',\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text}',\n",
    "    textposition='outside'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data['content_clean'].apply(lambda x: len(x.split()))\n",
    "\n",
    "fig_hist = px.histogram(\n",
    "    data, \n",
    "    x='word_count', \n",
    "    title='Word Count Distribution',\n",
    "    nbins=50,\n",
    "    labels={'word_count': 'Word Count'},\n",
    "    color_discrete_sequence=['blue']\n",
    ")\n",
    "fig_hist.update_layout(title_x=0.5)\n",
    "fig_hist.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter = px.scatter(\n",
    "    data, \n",
    "    x='word_count', \n",
    "    y='sentiment', \n",
    "    title='Sentiment by Word Count',\n",
    "    color='sentiment',\n",
    "    labels={'word_count': 'Word Count', 'sentiment': 'Sentiment'},\n",
    "    color_discrete_map={'positive': 'green', 'neutral': 'orange', 'negative': 'red'}\n",
    ")\n",
    "fig_scatter.update_layout(title_x=0.5)\n",
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text = \" \".join(data[data['sentiment'] == 'positive']['content_clean'])\n",
    "neutral_text = \" \".join(data[data['sentiment'] == 'neutral']['content_clean'])\n",
    "negative_text = \" \".join(data[data['sentiment'] == 'negative']['content_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(text, title, color):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white', \n",
    "        colormap=color,\n",
    "        max_words=200\n",
    "    ).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(positive_text, \"Word Cloud for Positive Sentiments\", \"Greens\")\n",
    "generate_wordcloud(neutral_text, \"Word Cloud for Neutral Sentiments\", \"Oranges\")\n",
    "generate_wordcloud(negative_text, \"Word Cloud for Negative Sentiments\", \"Reds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Word Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unique_word_count'] = data['content_clean'].apply(lambda x: len(set(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_unique = px.histogram(\n",
    "    data, \n",
    "    x='unique_word_count', \n",
    "    title='Unique Word Count Distribution',\n",
    "    nbins=50,\n",
    "    labels={'unique_word_count': 'Unique Word Count'},\n",
    "    color_discrete_sequence=['purple']\n",
    ")\n",
    "\n",
    "fig_unique.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Proportion by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_bar_score = px.histogram(\n",
    "    data, \n",
    "    x='score', \n",
    "    color='sentiment', \n",
    "    barmode='group',\n",
    "    title='Sentiment by Rating',\n",
    "    labels={'score': 'Score', 'count': 'Number of Reviews'},\n",
    "    color_discrete_map={'positive': 'green', 'neutral': 'orange', 'negative': 'red'}\n",
    ")\n",
    "\n",
    "fig_bar_score.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['at']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data.groupby(['date', 'sentiment']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_time = px.line(\n",
    "    grouped_data,\n",
    "    x='date',\n",
    "    y='count',\n",
    "    color='sentiment',\n",
    "    title='Sentiments Over Time',\n",
    "    labels={'date': 'Date', 'count': 'Number of Reviews'},\n",
    "    color_discrete_map={'Positive': 'green', 'Neutral': 'orange', 'Negative': 'red'}\n",
    ")\n",
    "\n",
    "fig_time.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(data, sentiment, n=10):\n",
    "    sentiment_data = data[data['sentiment'] == sentiment]\n",
    "    all_words = [word for tokens in sentiment_data['content_lemmatized'] for word in tokens]\n",
    "    word_counts = Counter(all_words)\n",
    "    return word_counts.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive = get_top_words(data, 'positive', n=10)\n",
    "top_neutral = get_top_words(data, 'neutral', n=10)\n",
    "top_negative = get_top_words(data, 'negative', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = pd.DataFrame(top_positive, columns=['word', 'count'])\n",
    "\n",
    "fig_positive = px.bar(\n",
    "    df_positive,\n",
    "    x='word',\n",
    "    y='count',\n",
    "    title='Top Words for Positive Sentiment',\n",
    "    labels={'word': 'Word', 'count': 'Frequency'},\n",
    "    color_discrete_sequence=['green']\n",
    ")\n",
    "\n",
    "fig_positive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neutral = pd.DataFrame(top_neutral, columns=['word', 'count'])\n",
    "\n",
    "fig_neutral = px.bar(\n",
    "    df_neutral,\n",
    "    x='word',\n",
    "    y='count',\n",
    "    title='Top Words for Neutral Sentiment',\n",
    "    labels={'word': 'Word', 'count': 'Frequency'},\n",
    "    color_discrete_sequence=['orange']\n",
    ")\n",
    "fig_neutral.update_layout(title_x=0.5)\n",
    "fig_neutral.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = pd.DataFrame(top_negative, columns=['word', 'count'])\n",
    "\n",
    "fig_negative = px.bar(\n",
    "    df_negative,\n",
    "    x='word',\n",
    "    y='count',\n",
    "    title='Top Words for Negative Sentiment',\n",
    "    labels={'word': 'Word', 'count': 'Frequency'},\n",
    "    color_discrete_sequence=['red']\n",
    ")\n",
    "\n",
    "fig_negative.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing\n",
    "In this process, Synthetic Minority Over-sampling Technique (SMOTE) is applied to balance the sentiment classification dataset. SMOTE generates synthetic samples for the minority classes (e.g., neutral or positive sentiment) to ensure a more balanced distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['sentiment_label'] = data['sentiment'].map({'negative': 0, 'positive': 1, 'neutral': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer()\n",
    "#X_tfidf = vectorizer.fit_transform(data['content_clean'])\n",
    "#y = data['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_labels = pd.DataFrame({'sentiment_smote': y_resampled})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([data, smote_labels.iloc[:len(data)]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "10000 feature dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = vectorizer_tfidf.fit_transform(data['content_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['sentiment'] = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['sentiment_numeric'] = label_encoder.fit_transform(tfidf_df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.drop(columns=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText\n",
    "300 feature dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_dir = \"../models/fasttext_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_path = os.path.join(fasttext_dir, \"fasttext.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(fasttext_path):\n",
    "    print(\"Download model FastText.\")\n",
    "    \n",
    "    fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "    fasttext_model.save(fasttext_path)\n",
    "    \n",
    "    print(f\"FastText model successfully saved in {fasttext_path}\")\n",
    "else:\n",
    "    print(\"FastText model already exists, no need to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = KeyedVectors.load(fasttext_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_vector(text):\n",
    "    words = text.split()\n",
    "    vectors = [fasttext_model[word] for word in words if word in fasttext_model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fasttext_features'] = data['content_clean'].apply(get_fasttext_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_df = pd.DataFrame(data['fasttext_features'].tolist(), columns=[f'fasttext_{i}' for i in range(300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_fasttext = pd.concat([data, fasttext_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_fasttext.drop(columns=['fasttext_features'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_fasttext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndoBERT\n",
    "768 feature dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indobert_dir = \"../models/indobert_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(indobert_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists(os.path.join(indobert_dir, \"pytorch_model.bin\")):\n",
    "#    print(\"Download model IndoBERT.\")\n",
    "#\n",
    "#    tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "#    model = BertModel.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "#\n",
    "#    tokenizer.save_pretrained(indobert_dir)\n",
    "#    model.save_pretrained(indobert_dir)\n",
    "#\n",
    "#    print(f\"IndoBERT model successfully saved in {indobert_dir}\")\n",
    "#else:\n",
    "#    print(\"IndoBERT model already exists, no need to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained(indobert_dir)\n",
    "#model = BertModel.from_pretrained(indobert_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_bert_embedding(text):\n",
    "#    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#\n",
    "#    with torch.no_grad():\n",
    "#        outputs = model(**inputs)\n",
    "#\n",
    "#    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['bert_features'] = data['content_clean'].apply(get_bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert_df = pd.DataFrame(data['bert_features'].tolist(), columns=[f'bert_{i}' for i in range(768)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_with_bert = pd.concat([data, bert_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_with_bert.drop(columns=['bert_features'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_with_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 20000\n",
    "MAX_LENGTH = 100\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(data['content_clean'])\n",
    "X_sequences = tokenizer.texts_to_sequences(data['content_clean'])\n",
    "X_padded = pad_sequences(X_sequences, maxlen=MAX_LENGTH)\n",
    "y_labels = data['sentiment_numeric'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, model_name):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    # Plot Loss\n",
    "    axs[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axs[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axs[0].set_title(f'{model_name} Loss')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "    # Plot Accuracy\n",
    "    axs[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axs[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    axs[1].set_title(f'{model_name} Accuracy')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_training_history.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_features = tfidf_df.drop(columns=['sentiment_numeric']).values\n",
    "y_tfidf = tfidf_df['sentiment_numeric'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fasttext = fasttext_df.values\n",
    "y_fasttext = data['sentiment_numeric'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_svm, X_test_tfidf_svm, y_train_tfidf_svm, y_test_tfidf_svm = train_test_split(\n",
    "    X_tfidf_features, y_tfidf, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tfidf_svm(trial):\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"])\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n",
    "    if kernel == \"rbf\":\n",
    "        gamma = trial.suggest_loguniform(\"gamma\", 1e-4, 1e-1)\n",
    "        model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)\n",
    "    else:\n",
    "        model = SVC(kernel=kernel, C=C, random_state=42)\n",
    "    \n",
    "    model.fit(X_train_tfidf_svm, y_train_tfidf_svm)\n",
    "    y_pred = model.predict(X_test_tfidf_svm)\n",
    "    return accuracy_score(y_test_tfidf_svm, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_tfidf_svm = optuna.create_study(direction=\"maximize\")\n",
    "study_tfidf_svm.optimize(objective_tfidf_svm, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_tfidf_svm, \"../models/svm/tfidf_svm_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best TF-IDF SVM hyperparameters:\", study_tfidf_svm.best_params)\n",
    "print(\"Best TF-IDF SVM Accuracy (Validation): {:.4f}\".format(study_tfidf_svm.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_tfidf_svm = study_tfidf_svm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_params_tfidf_svm[\"kernel\"] == \"rbf\":\n",
    "    best_model_tfidf_svm = SVC(kernel=best_params_tfidf_svm[\"kernel\"], C=best_params_tfidf_svm[\"C\"], gamma=best_params_tfidf_svm[\"gamma\"], random_state=42)\n",
    "else:\n",
    "    best_model_tfidf_svm = SVC(kernel=best_params_tfidf_svm[\"kernel\"], C=best_params_tfidf_svm[\"C\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_tfidf_svm.fit(X_train_tfidf_svm, y_train_tfidf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_tfidf_svm = best_model_tfidf_svm.predict(X_train_tfidf_svm)\n",
    "y_test_pred_tfidf_svm = best_model_tfidf_svm.predict(X_test_tfidf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_tfidf_svm = accuracy_score(y_train_tfidf_svm, y_train_pred_tfidf_svm)\n",
    "test_acc_tfidf_svm = accuracy_score(y_test_tfidf_svm, y_test_pred_tfidf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF-IDF + SVM Training Accuracy: {:.4f}\".format(train_acc_tfidf_svm))\n",
    "print(\"TF-IDF + SVM Testing Accuracy:  {:.4f}\".format(test_acc_tfidf_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_tfidf_svm, y_test_pred_tfidf_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model_tfidf_svm, \"../models/svm/best_tfidf_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fasttext_svm, X_test_fasttext_svm, y_train_fasttext_svm, y_test_fasttext_svm = train_test_split(\n",
    "    X_fasttext, y_fasttext, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fasttext_svm(trial):\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"])\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n",
    "    if kernel == \"rbf\":\n",
    "        gamma = trial.suggest_loguniform(\"gamma\", 1e-4, 1e-1)\n",
    "        model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)\n",
    "    else:\n",
    "        model = SVC(kernel=kernel, C=C, random_state=42)\n",
    "    \n",
    "    model.fit(X_train_fasttext_svm, y_train_fasttext_svm)\n",
    "    y_pred = model.predict(X_test_fasttext_svm)\n",
    "    return accuracy_score(y_test_fasttext_svm, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_fasttext_svm = optuna.create_study(direction=\"maximize\")\n",
    "study_fasttext_svm.optimize(objective_fasttext_svm, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_fasttext_svm, \"../models/svm/fasttext_svm_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best FastText SVM hyperparameters:\", study_fasttext_svm.best_params)\n",
    "print(\"Best FastText SVM Accuracy (Validation): {:.4f}\".format(study_fasttext_svm.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_fasttext_svm = study_fasttext_svm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_params_fasttext_svm[\"kernel\"] == \"rbf\":\n",
    "    best_model_fasttext_svm = SVC(kernel=best_params_fasttext_svm[\"kernel\"], C=best_params_fasttext_svm[\"C\"], gamma=best_params_fasttext_svm[\"gamma\"], random_state=42)\n",
    "else:\n",
    "    best_model_fasttext_svm = SVC(kernel=best_params_fasttext_svm[\"kernel\"], C=best_params_fasttext_svm[\"C\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fasttext_svm.fit(X_train_fasttext_svm, y_train_fasttext_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_fasttext_svm = best_model_fasttext_svm.predict(X_train_fasttext_svm)\n",
    "y_test_pred_fasttext_svm = best_model_fasttext_svm.predict(X_test_fasttext_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_fasttext_svm = accuracy_score(y_train_fasttext_svm, y_train_pred_fasttext_svm)\n",
    "test_acc_fasttext_svm = accuracy_score(y_test_fasttext_svm, y_test_pred_fasttext_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FastText + SVM Training Accuracy: {:.4f}\".format(train_acc_fasttext_svm))\n",
    "print(\"FastText + SVM Testing Accuracy:  {:.4f}\".format(test_acc_fasttext_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_fasttext_svm, y_test_pred_fasttext_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model_fasttext_svm, \"../models/svm/best_fasttext_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_rf, X_test_tfidf_rf, y_train_tfidf_rf, y_test_tfidf_rf = train_test_split(\n",
    "    X_tfidf_features, y_tfidf, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tfidf_rf(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split, \n",
    "                                   random_state=42)\n",
    "    model.fit(X_train_tfidf_rf, y_train_tfidf_rf)\n",
    "    y_pred = model.predict(X_test_tfidf_rf)\n",
    "    return accuracy_score(y_test_tfidf_rf, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_tfidf_rf = optuna.create_study(direction=\"maximize\")\n",
    "study_tfidf_rf.optimize(objective_tfidf_rf, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_tfidf_rf, \"../models/rf/tfidf_rf_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best TF-IDF RF hyperparameters:\", study_tfidf_rf.best_params)\n",
    "print(\"Best TF-IDF RF Accuracy (Validation): {:.4f}\".format(study_tfidf_rf.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_tfidf_rf = study_tfidf_rf.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_tfidf_rf = RandomForestClassifier(n_estimators=best_params_tfidf_rf[\"n_estimators\"],\n",
    "                                             max_depth=best_params_tfidf_rf[\"max_depth\"],\n",
    "                                             min_samples_split=best_params_tfidf_rf[\"min_samples_split\"],\n",
    "                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_tfidf_rf.fit(X_train_tfidf_rf, y_train_tfidf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_tfidf_rf = best_model_tfidf_rf.predict(X_train_tfidf_rf)\n",
    "y_test_pred_tfidf_rf = best_model_tfidf_rf.predict(X_test_tfidf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_tfidf_rf = accuracy_score(y_train_tfidf_rf, y_train_pred_tfidf_rf)\n",
    "test_acc_tfidf_rf = accuracy_score(y_test_tfidf_rf, y_test_pred_tfidf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF-IDF + Random Forest Training Accuracy: {:.4f}\".format(train_acc_tfidf_rf))\n",
    "print(\"TF-IDF + Random Forest Testing Accuracy:  {:.4f}\".format(test_acc_tfidf_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_tfidf_rf, y_test_pred_tfidf_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model_tfidf_rf, \"../models/rf/best_tfidf_rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fasttext_rf, X_test_fasttext_rf, y_train_fasttext_rf, y_test_fasttext_rf = train_test_split(\n",
    "    X_fasttext, y_fasttext, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fasttext_rf(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split, \n",
    "                                   random_state=42)\n",
    "    model.fit(X_train_fasttext_rf, y_train_fasttext_rf)\n",
    "    y_pred = model.predict(X_test_fasttext_rf)\n",
    "    return accuracy_score(y_test_fasttext_rf, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_fasttext_rf = optuna.create_study(direction=\"maximize\")\n",
    "study_fasttext_rf.optimize(objective_fasttext_rf, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_fasttext_rf, \"../models/rf/fasttext_rf_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best FastText RF hyperparameters:\", study_fasttext_rf.best_params)\n",
    "print(\"Best FastText RF Accuracy (Validation): {:.4f}\".format(study_fasttext_rf.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_fasttext_rf = study_fasttext_rf.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fasttext_rf = RandomForestClassifier(n_estimators=best_params_fasttext_rf[\"n_estimators\"],\n",
    "                                                max_depth=best_params_fasttext_rf[\"max_depth\"],\n",
    "                                                min_samples_split=best_params_fasttext_rf[\"min_samples_split\"],\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fasttext_rf.fit(X_train_fasttext_rf, y_train_fasttext_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_fasttext_rf = best_model_fasttext_rf.predict(X_train_fasttext_rf)\n",
    "y_test_pred_fasttext_rf = best_model_fasttext_rf.predict(X_test_fasttext_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_fasttext_rf = accuracy_score(y_train_fasttext_rf, y_train_pred_fasttext_rf)\n",
    "test_acc_fasttext_rf = accuracy_score(y_test_fasttext_rf, y_test_pred_fasttext_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FastText + Random Forest Training Accuracy: {:.4f}\".format(train_acc_fasttext_rf))\n",
    "print(\"FastText + Random Forest Testing Accuracy:  {:.4f}\".format(test_acc_fasttext_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_fasttext_rf, y_test_pred_fasttext_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model_fasttext_rf, \"../models/rf/best_fasttext_rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_padded, y_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cnn(trial):\n",
    "    filters = trial.suggest_categorical(\"filters\", [128, 256])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 1.0)\n",
    "    l2_lambda = trial.suggest_float(\"l2_lambda\", 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LENGTH),\n",
    "        Conv1D(filters=filters, kernel_size=5, activation='relu', kernel_regularizer=L2(l2_lambda)),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu', kernel_regularizer=L2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=64, validation_data=(X_test_cnn, y_test_cnn),\n",
    "              verbose=0, callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)])\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cnn = optuna.create_study(direction=\"maximize\")\n",
    "study_cnn.optimize(objective_cnn, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_cnn, \"../models/cnn/cnn_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best CNN Hyperparameters: {study_cnn.best_params}\")\n",
    "print(f\"Best CNN Accuracy: {study_cnn.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_cnn = study_cnn.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_best = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LENGTH),\n",
    "    Conv1D(filters=best_params_cnn['filters'], kernel_size=5, activation='relu', kernel_regularizer=L2(best_params_cnn['l2_lambda'])),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dropout(best_params_cnn['dropout']),\n",
    "    Dense(64, activation='relu', kernel_regularizer=L2(best_params_cnn['l2_lambda'])),\n",
    "    Dropout(best_params_cnn['dropout']),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_best.compile(optimizer=Adam(learning_rate=best_params_cnn['learning_rate']), \n",
    "                 loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn = cnn_best.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=64, \n",
    "                           validation_data=(X_test_cnn, y_test_cnn), \n",
    "                           callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_cnn, train_acc_cnn = cnn_best.evaluate(X_train_cnn, y_train_cnn, verbose=0)\n",
    "test_loss_cnn, test_acc_cnn = cnn_best.evaluate(X_test_cnn, y_test_cnn, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CNN Training Accuracy: {train_acc_cnn:.4f}\")\n",
    "print(f\"CNN Testing Accuracy: {test_acc_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_best.save(\"../models/cnn/best_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_cnn, \"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_padded, y_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial):\n",
    "    lstm_units = trial.suggest_categorical(\"lstm_units\", [128, 256])\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 1.0)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 5e-3, log=True)\n",
    "    l2_lambda = trial.suggest_float(\"l2_lambda\", 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LENGTH),\n",
    "        Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout_rate, kernel_regularizer=L2(l2_lambda))),\n",
    "        Bidirectional(LSTM(lstm_units // 2, dropout=dropout_rate, kernel_regularizer=L2(l2_lambda))),\n",
    "        Dense(64, activation='relu', kernel_regularizer=L2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=64, validation_data=(X_test_lstm, y_test_lstm), \n",
    "              verbose=0, callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)])\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lstm = optuna.create_study(direction=\"maximize\")\n",
    "study_lstm.optimize(objective_lstm, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_lstm, \"../models/lstm/lstm_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best LSTM Hyperparameters: {study_lstm.best_params}\")\n",
    "print(f\"Best LSTM Accuracy: {study_lstm.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lstm = study_lstm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_best = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LENGTH),\n",
    "    Bidirectional(LSTM(best_params_lstm['lstm_units'], return_sequences=True, dropout=best_params_lstm['dropout'], kernel_regularizer=L2(best_params_lstm['l2_lambda']))),\n",
    "    Bidirectional(LSTM(best_params_lstm['lstm_units'] // 2, dropout=best_params_lstm['dropout'], kernel_regularizer=L2(best_params_lstm['l2_lambda']))),\n",
    "    Dense(64, activation='relu', kernel_regularizer=L2(best_params_lstm['l2_lambda'])),\n",
    "    Dropout(best_params_lstm['dropout']),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_best.compile(optimizer=Adam(learning_rate=best_params_lstm['learning_rate']),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm = lstm_best.fit(X_train_lstm, y_train_lstm, epochs=15, batch_size=64, validation_data=(X_test_lstm, y_test_lstm),\n",
    "                             callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_lstm, train_acc_lstm = lstm_best.evaluate(X_train_lstm, y_train_lstm, verbose=0)\n",
    "test_loss_lstm, test_acc_lstm = lstm_best.evaluate(X_test_lstm, y_test_lstm, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LSTM Training Accuracy: {train_acc_lstm:.4f}\")\n",
    "print(f\"LSTM Testing Accuracy: {test_acc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_best.save(\"../models/lstm/best_lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_lstm, \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gru, X_test_gru, y_train_gru, y_test_gru = train_test_split(X_padded, y_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gru(trial):\n",
    "    gru_units = trial.suggest_categorical(\"gru_units\", [128, 256])\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 1.0)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 5e-3, log=True)\n",
    "    l2_lambda = trial.suggest_float(\"l2_lambda\", 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LENGTH),\n",
    "        Bidirectional(GRU(gru_units, return_sequences=True, dropout=dropout_rate, kernel_regularizer=L2(l2_lambda))),\n",
    "        Bidirectional(GRU(gru_units // 2, dropout=dropout_rate, kernel_regularizer=L2(l2_lambda))),\n",
    "        Dense(64, activation='relu', kernel_regularizer=L2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train_gru, y_train_gru, epochs=10, batch_size=64, validation_data=(X_test_gru, y_test_gru),\n",
    "              verbose=0, callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)])\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_test_gru, y_test_gru, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_gru = optuna.create_study(direction=\"maximize\")\n",
    "study_gru.optimize(objective_gru, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study_gru, \"../models/gru/gru_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best GRU Hyperparameters: {study_gru.best_params}\")\n",
    "print(f\"Best GRU Accuracy: {study_gru.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_gru = study_gru.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_best = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LENGTH),\n",
    "    Bidirectional(GRU(best_params_gru['gru_units'], return_sequences=True, dropout=best_params_gru['dropout'], kernel_regularizer=L2(best_params_gru['l2_lambda']))),\n",
    "    Bidirectional(GRU(best_params_gru['gru_units'] // 2, dropout=best_params_gru['dropout'], kernel_regularizer=L2(best_params_gru['l2_lambda']))),\n",
    "    Dense(64, activation='relu', kernel_regularizer=L2(best_params_gru['l2_lambda'])),\n",
    "    Dropout(best_params_gru['dropout']),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_best.compile(optimizer=Adam(learning_rate=best_params_gru['learning_rate']),\n",
    "                 loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gru = gru_best.fit(X_train_gru, y_train_gru, epochs=15, batch_size=64, validation_data=(X_test_gru, y_test_gru),\n",
    "                           callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_gru, train_acc_gru = gru_best.evaluate(X_train_gru, y_train_gru, verbose=0)\n",
    "test_loss_gru, test_acc_gru = gru_best.evaluate(X_test_gru, y_test_gru, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GRU Training Accuracy: {train_acc_gru:.4f}\")\n",
    "print(f\"GRU Testing Accuracy: {test_acc_gru:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_best.save(\"../models/gru/best_gru_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_gru, \"GRU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Testing & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acc = {\n",
    "    \"Model\": [\n",
    "        \"SVM TF-IDF\", \"SVM TF-IDF\",\n",
    "        \"SVM FastText\", \"SVM FastText\",\n",
    "        \"RF TF-IDF\", \"RF TF-IDF\",\n",
    "        \"RF FastText\", \"RF FastText\",\n",
    "        \"CNN\", \"CNN\",\n",
    "        \"LSTM\", \"LSTM\",\n",
    "        \"GRU\", \"GRU\"\n",
    "    ],\n",
    "    \"Dataset\": [\n",
    "        \"Train\", \"Test\",\n",
    "        \"Train\", \"Test\",\n",
    "        \"Train\", \"Test\",\n",
    "        \"Train\", \"Test\",\n",
    "        \"Train\", \"Test\",\n",
    "        \"Train\", \"Test\",\n",
    "        \"Train\", \"Test\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        train_acc_tfidf_svm, test_acc_tfidf_svm,\n",
    "        train_acc_fasttext_svm, test_acc_fasttext_svm,\n",
    "        train_acc_tfidf_rf, test_acc_tfidf_rf,\n",
    "        train_acc_fasttext_rf, test_acc_fasttext_rf,\n",
    "        train_acc_cnn, test_acc_cnn,\n",
    "        train_acc_lstm, test_acc_lstm,\n",
    "        train_acc_gru, test_acc_gru\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.DataFrame(data_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\"SVM TF-IDF\", \"SVM FastText\", \"RF TF-IDF\", \"RF FastText\", \"CNN\", \"LSTM\", \"GRU\"]\n",
    "df_acc[\"Model\"] = pd.Categorical(df_acc[\"Model\"], categories=model_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_acc,\n",
    "    x=\"Model\",\n",
    "    y=\"Accuracy\",\n",
    "    color=\"Dataset\",\n",
    "    barmode=\"group\",\n",
    "    title=\"Comparison of Training and Testing Accuracy\",\n",
    "    text=\"Accuracy\"\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
